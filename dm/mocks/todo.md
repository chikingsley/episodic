Below is a pragmatic â€œnext-mileâ€ brief.
I kept it intentionally high-signal so you (or the devs you hand this to) can paste it into Linear/Jira and start carving tickets.

â¸»

1â€‚What youâ€™re actually describing

â€œHard-line Pimsleur spine, but allow the system to ask the learner to re-do a day, inject extra context, etc. Less 40-dimensional chess; more â€˜help me if Iâ€™m shakyâ€™.â€

Thatâ€™s a Scripted-Spine + Adaptive Overlay pattern:

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      always unlocked
â”‚  Day-N Pimsleur audio â”‚  â”€â–º  (fixed chronology, 30 min chunks)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

          â–¼ when overlay says â€œyesâ€
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Adaptive Overlay  (HLR + Elo)                        â”‚
â”‚  â€¢ inserts â‰¤ 6  min of micro-reviews                   â”‚
â”‚  â€¢ OR asks learner to â€œre-take yesterdayâ€™s episode     â”‚
â”‚    with extra promptsâ€ if P(recall)<.60                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

	â€¢	Spine = complete Pimsleur scripts, chopped into call-&-response item_ids.
	â€¢	Overlay = pure HLR (or HLR + Elo if you want to choose which prompt to review).
When the overlay fires, you can either:

	1.	prepend a â€œre-listenâ€ version of yesterdayâ€™s chunk, or
	2.	insert extra call-&-response prompts inside todayâ€™s session.

That gives you:
	â€¢	The psychological safety of familiar Pimsleur pacing.
	â€¢	Evidence-based review whenever the memory curve predicts failure.
	â€¢	Zero need for full generative exercises on day 1â€”youâ€™re just replaying existing audio or re-ordering prompts.

â¸»

2â€‚Cold-start / seeding checklist (v0.2 schema)

what must exist before the first user can press Start	how many do you really need?
language rows	1 per language (e.g. fr)
1 section â†’ 1 unit â†’ 1 lesson to satisfy FK cascade	create â€œPilot / Unit 0 / Lesson 0â€ dummy rows if needed
exercise templates (template_id 1-5)	as many as you support in UI
item + concept records for every prompt in the first 30-min audio	200-300 lines is plenty
audio chunk metadata (media_asset)	one row per call/partner voice segment
seed A/B parameters for HLR (A=0, B=0.5) + Elo (d=0)	automated default

Everything else is auto-created the first time a learner triggers it.

â¸»

3â€‚Minimal back-end jobs you can postpone

job	can you launch without it?	when to add
Nightly Elo replay	Yes	after you have > 50 k events and want stable leaderboards
Tier-decay cron	Yes	when you introduce visible lesson tiers
Gem refill cron	Yes	when hearts/gems actually gate play
Leaderboard snapshot	Yes	when you expose a leaderboard



â¸»

4â€‚High-level task board

4.1 Core APIs (Convex/Supabase)

endpoint / fn	job
startSession(user_id)	open session, returns daily_goal, etc.
nextPrompt(session_id)	chooses overlay vs spine prompt, returns media + template
submitAnswer(event_payload)	writes user_exercise_event, runs Eq 1-5, returns next_due + XP
endSession(session_id)	close, update streak, wallet

All maths (Elo, HLR) live in this layer.

â¸»

4.2 React-Native UI surface areas

screen / component	data needed from schema
Home map / path	unit, lesson, user_lesson.best_tier, streak
Audio Player (Pimsleur)	ordered list of media_asset & expected_text (for STT check)
Review modal	overlay picks; simple â€œSay it againâ€ or multiple-choice template
XP / Gem toast	output of submitAnswer
Streak & wallet bar	streak, wallet
Settings / debug	surface elo_user_global, p_recall (nice for power users)

Speech: Use expo-speech for TTS (partner voice) and expo-speech-recognition (or native iOS / Android recognizers) for STT. Capture transcript; Levenshtein â‰¤ 30 % â†’ marked â€œcorrectâ€.

â¸»

4.3 Content-author tooling

tool	must-haves
CSV â†’ SQL uploader	headers match item, exercise, media_asset
Audio chunk marker	small in-house script: drop an .mp3, click â€œsplitâ€, export rows with start_ms, end_ms, file_url
Script previewer	web page that plays partner line â–¶ TTS narrator â–¶ records learner â–¶



â¸»

4.4 Optional niceties
	â€¢	Rive animations: show a mouth-moving avatar on speak templates.
Hook listener.isRecording â†’ play â€œspeakingâ€ state machine.
	â€¢	Pipecat Cloud: wrap the STT error messageâ€”if transcript far off, call Pipecat to generate a corrective hint.
Thatâ€™s bolt-on; not schema-critical.
	â€¢	Pronunciation depth:
Word level: iOS & Android recognizers give timing per token â‡’ highlight wrong syllable.
Phoneme level: open-source pocketsphinx-align or paid Google Cloud Speech phone-infoâ€”only if you want red-/green per phoneme.
Totally optional for v1.

â¸»

5â€‚Ticket template cheat-sheet

feat(content): ingest Pimsleur Lesson 01
  â€¢ provide CSV for item / exercise / media_asset
  â€¢ run chunk-marker -> produce 120 media rows
  â€¢ verify in script previewer

feat(api): POST /submitAnswer
  â€¢ validate payload against user_exercise_event
  â€¢ run Eq1-3, Eq5
  â€¢ return {xp_delta, hearts_delta, next_prompt}

feat(ui): AudioPlayer
  â€¢ renders list of mediaAsset[]
  â€¢ after partner/narrator line, auto-record learner
  â€¢ onComplete => call /submitAnswer



â¸»

6â€‚Sanity path to â€œHello Worldâ€
	1.	Insert language â†’ section â†’ unit â†’ lesson rows.
	2.	Load 1 dialogue with ~10 call-&-response lines as item + exercise.
	3.	Mock overlay OFF (always returns next spine prompt).
	4.	Build AudioPlayer that just plays the 10 lines and records STT.
	5.	Wire submitAnswer â†’ writes user_exercise_event, updates Elo.
	6.	Show XP toast.
	7.	Doneâ€”first learner can finish Lesson 0 and see streak ğŸ“ˆ.

Everything else (overlay review, wallet, Rive, concept-Elo, Gem shop, nightly jobs) layers on without schema changes.

â¸»

Remember

You donâ€™t need â€œcrazy under-the-hoodâ€ on day 1.
The spine already teaches; the overlay only intervenes when memory curves predict pain.

Ship the narrow slice above, watch real learners struggle, then crank up the clever bits.